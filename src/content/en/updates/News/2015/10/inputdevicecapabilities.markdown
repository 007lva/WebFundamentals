---
layout: updates/post
title: "Input Device Capabilities"
published_on: 2015-10-15
updated_on: 2015-10-15
authors:
  - paulkinlan
tags:
  - input
featured_image: /web/updates/images/2015/10/inputdevicecapabilities.png
description: "A simpler method to rationalize your mouse and touch logic for when there is no PointerEvents"
---

Chrome 47 has a new feature that make it easier to understand the how the users 
can interact with your site. 
[InputDeviceCapabilities](http://rbyers.github.io/InputDevice/)! But let's step 
back a bit and work out why this is important.

DOM input events are an abstraction above low-level input events, loosely tied 
to physical device input (e.g. `click` events can be fired by a mouse, 
touchscreen or keyboard). However there is a problem: there is no simple method 
to obtain the details of the physical device responsible for an event. 

Added to this, certain types of input can also generate further "fake" DOM input 
events for compatibility reasons. One such fake DOM event is what happens when a 
user taps a touch screen (such as one on a mobile phone), it not only fire touch 
events, but for compatibility reasons mouse events are also generated. 

This causes developers problems when supporting both mouse and touch input, it's 
difficult to know if a `mousedown` event represents new input from a mouse, or 
a compatibility event for a previously processed touchstart event.

The new `InputDeviceCapabilities` API provides details about the underlying 
sources of input events via a `sourceCapabilities` object on the UIEvent that 
has a `firesTouchEvents` property set to `true` or `false` based on how 
the event was generated by the user action.    
So... the question is: Where should this be used?

Great question.  Outside of Pointer Events many developers today handle the 
logic for interaction either in the touch-layer, preventing Default to avoid 
creating "fake" mouse events in the first place.  This design works well in many 
scenarios and doesn't need to change to take advantage of 
InputDeviceCapabilities.

But in some scenarios you really don't want to preventDefault the touch event, 
for example you still want tapping to send 'click' events and change focus.  For 
these cases, the information held in the 
`MouseEvent.sourceCapabilities.firesTouchEvents` property allows you to start 
rationalising the logic for touch event and mouse based into a model that is 
_similar_ to how you would manage the logic with Pointer Events, i.e, have one 
set of code that manages the interaction logic and provides developers a simpler 
way to share logic between browsers that do and don't support Pointer Events.

{% highlight javascript %}
function addMouseEventListener(target, type, handler, capture) {  
  target.addEventListener(type, function(e) {  
    if (e.sourceCapabilities.firesTouchEvents)  
      return false;  
    return handler(e);  
  }, capture);  
}
{% endhighlight %}

The good news is that this has been 
[Polyfilled](https://github.com/RByers/InputDevice/blob/gh-pages/inputdevicecapabilities-polyfill.js) 
by Rick Byers so that you can use this across most platforms.

Today this API is minimal, focused on solving [a specific problem with 
identifying mouse events derived from touch 
events](https://docs.google.com/document/d/1-ZUtS3knhJP4RbWC74fUZbNp6cbytG6Wen7hewdCtdo/edit#heading=h.4my5f1pokrld). 
 It is even possible to instantiate an instance of `InputDeviceCapabilities` 
however it only contains `firesTouchEvents`, in the future it's expected that 
to 
[expand](http://discourse.wicg.io/t/additional-use-cases-for-inputdevicecapabilities/1138) 
to enable you to understand more about all of the input devices on a user's 
system and we would love to get your feedback on 
[usecases](http://discourse.wicg.io/t/inputdevice-api-for-identifying-mouse-events-derived-from-touch/972).
